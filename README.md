# Machine Learning Project Report: Loan Eligibility Prediction

## 1. Dataset Description
The dataset used is the **Loan Prediction Dataset**, consisting of **614 records** and **13 features**. The objective is to automate the loan approval process by predicting the `Loan_Status` (Yes/No).

**Preprocessing & Feature Engineering:**
* **Feature Creation:** A new feature `TotalIncome` was generated by summing `ApplicantIncome` and `CoapplicantIncome` to capture the complete financial strength of the applicant's household.
* **Outlier Handling:** A high-income outlier (81,000) was identified. Instead of deletion, it was retained to act as a "hard negative" (high income but rejected), teaching the model nuance.
* **Pipeline Implementation:**
    * **Ordinal Encoding:** Applied to `Gender`, `Married`, and `Education` to preserve binary relationships (e.g., Graduate > Not Graduate).
    * **One-Hot Encoding:** Applied to nominal variables like `Property_Area`.
    * **Imputation:** Missing values were filled using the **Mode** for categorical/discrete variables (like `Loan_Amount_Term`) and the **Mean** for continuous variables.
    * **Scaling:** All numeric features were standardized using `StandardScaler` to ensure convergence for Logistic Regression.

---

## 2. Methodology
A comprehensive machine learning pipeline was implemented to compare linear, non-linear, and ensemble algorithms. The workflow utilized Scikit-Learn's `Pipeline` and `ColumnTransformer` to prevent data leakage.

### Models Evaluated
1.  **Logistic Regression:** A linear baseline utilizing L1 regularization (Lasso) to perform automatic feature selection.
2.  **Decision Tree:** A non-linear model tuned for depth (`max_depth`) to prevent overfitting and capture simple decision boundaries.
3.  **Random Forest:** A bagging ensemble method used to reduce variance and improve stability by averaging multiple decision trees.
4.  **AdaBoost:** A boosting ensemble designed to reduce bias by iteratively correcting the errors of weak learners.

### Optimization Strategy
Hyperparameters were optimized using **GridSearchCV** with 5-fold cross-validation:
* **Logistic Regression:** Tuned `C` (inverse regularization strength) and `penalty` type.
* **Tree Models:** Tuned `max_depth`, `min_samples_split`, and `n_estimators` to balance model complexity and generalization.

---

## 3. Results and Analysis
The models were evaluated on a held-out test set (30% of the data). The performance metrics are summarized below:

| Model | Accuracy | Precision | Recall | F1-Score | AUC |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Random Forest** | **80.0%** | **0.77** | **0.98** | **0.86** | **0.79** |
| **Logistic Regression** | 78.4% | 0.76 | 0.98 | 0.86 | 0.70 |
| **Decision Tree** | 78.4% | 0.76 | 0.98 | 0.86 | 0.71 |
| **AdaBoost** | 78.4% | 0.76 | 0.98 | 0.86 | 0.72 |

### Key Observations
* **Best Performer:** The **Random Forest** achieved the highest Accuracy (**80.0%**) and the highest AUC score (**0.79**), indicating it is the most robust model for ranking applicants and distinguishing between classes.
* **Convergence of Other Models:** Logistic Regression, Decision Tree, and AdaBoost all converged to the exact same Accuracy (78.4%) and Recall (98%). This suggests that the dataset contains strong primary signals (likely `Credit_History`) that are easily picked up by simpler models, but they lack the nuance to capture the edge cases that Random Forest solved.
* **High Recall:** All models achieved an exceptional **98% Recall**, meaning the system correctly identified almost all eligible applicants, minimizing the business risk of rejecting good customers.

---

## 4. Conclusion
The project successfully developed a reliable predictive model for loan eligibility.

* **Winner:** The **Random Forest** is the recommended model for deployment. Its ensemble nature allowed it to smooth out noise (including the retained high-income outlier) and capture complex non-linear patterns better than single trees or linear models.
* **Why it performed better:** While the single Decision Tree was prone to variance (overfitting/underfitting specific splits), the Random Forest averaged 800 trees to create a stable decision boundary. This resulted in a 1.6% accuracy gain and a significant improvement in AUC (+0.08) over the baseline models.
